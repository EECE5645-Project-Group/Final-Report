
@inproceedings{pottenger_role_1998,
	address = {Melbourne Australia},
	title = {The role of associativity and commutativity in the detection and transformation of loop-level parallelism},
	isbn = {978-0-89791-998-2},
	url = {https://dl.acm.org/doi/10.1145/277830.277870},
	doi = {10.1145/277830.277870},
	language = {en},
	urldate = {2023-12-09},
	booktitle = {Proceedings of the 12th international conference on {Supercomputing}},
	publisher = {ACM},
	author = {Pottenger, William M.},
	month = jul,
	year = {1998},
	pages = {188--195},
}

@misc{graham_fractional_2015,
	title = {Fractional {Max}-{Pooling}},
	url = {http://arxiv.org/abs/1412.6071},
	doi = {10.48550/arXiv.1412.6071},
	abstract = {Convolutional networks almost always incorporate some form of spatial pooling, and very often it is alpha times alpha max-pooling with alpha=2. Max-pooling act on the hidden layers of the network, reducing their size by an integer multiplicative factor alpha. The amazing by-product of discarding 75\% of your data is that you build into the network a degree of invariance with respect to translations and elastic distortions. However, if you simply alternate convolutional layers with max-pooling layers, performance is limited due to the rapid reduction in spatial size, and the disjoint nature of the pooling regions. We have formulated a fractional version of max-pooling where alpha is allowed to take non-integer values. Our version of max-pooling is stochastic as there are lots of different ways of constructing suitable pooling regions. We find that our form of fractional max-pooling reduces overfitting on a variety of datasets: for instance, we improve on the state-of-the art for CIFAR-100 without even using dropout.},
	urldate = {2023-12-09},
	publisher = {arXiv},
	author = {Graham, Benjamin},
	month = may,
	year = {2015},
	note = {arXiv:1412.6071 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{zhang_generalized_2018,
	title = {Generalized {Cross} {Entropy} {Loss} for {Training} {Deep} {Neural} {Networks} with {Noisy} {Labels}},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper_files/paper/2018/hash/f2925f97bc13ad2852a7a551802feea0-Abstract.html},
	abstract = {Deep neural networks (DNNs) have achieved tremendous success in a variety of applications across many disciplines. Yet, their superior performance comes with the expensive cost of requiring correctly annotated large-scale datasets. Moreover, due to DNNs' rich capacity, errors in training labels can hamper performance. To combat this problem, mean absolute error (MAE) has recently been proposed as a noise-robust alternative to the commonly-used categorical cross entropy (CCE) loss. However, as we show in this paper, MAE can perform poorly with DNNs and large-scale datasets. Here, we present a theoretically grounded set of noise-robust loss functions that can be seen as a generalization of MAE and CCE. Proposed loss functions can be readily applied with any existing DNN architecture and algorithm, while yielding good performance in a wide range of noisy label scenarios. We report results from experiments conducted with CIFAR-10, CIFAR-100 and FASHION-MNIST datasets and synthetically generated noisy labels.},
	urldate = {2023-12-09},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Zhang, Zhilu and Sabuncu, Mert},
	year = {2018},
}

@misc{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	doi = {10.48550/arXiv.1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2023-12-09},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv:1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{narayan_generalized_1997,
	title = {The generalized sigmoid activation function: {Competitive} supervised learning},
	volume = {99},
	issn = {0020-0255},
	shorttitle = {The generalized sigmoid activation function},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025596002009},
	doi = {10.1016/S0020-0255(96)00200-9},
	abstract = {Multilayer perceptron (MLP) networks trained using backpropagation are perhaps the most commonly used neural network model. Central to the MLP model is the use of neurons with nonlinear and differentiable activation functions. The most commonly used activation function is a sigmoidal function, and frequently all neurons in an MLP network employ the same activation function. In this paper, we introduce the notion of the generalized sigmoid as an activation function for neurons in the output layer of an MLP network. The enhancements afforded by the use of the generalized sigmoid are analyzed and demonstrated in the context of some well-known classification problems.},
	number = {1},
	urldate = {2023-12-09},
	journal = {Information Sciences},
	author = {Narayan, Sridhar},
	month = jun,
	year = {1997},
	pages = {69--82},
}

@article{klein_diabetic_1985,
	title = {Diabetic {Retinopathy} as {Detected} {Using} {Ophthalmoscopy}, a {Nonmyciriatic} {Camera} and a {Standard} {Fundus} {Camera}},
	volume = {92},
	issn = {0161-6420},
	url = {https://www.sciencedirect.com/science/article/pii/S0161642085340034},
	doi = {10.1016/S0161-6420(85)34003-4},
	abstract = {The study was performed to evaluate whether the severity of diabetic retinopathy as assessed by three alternative methods was concordant with the severity of retinopathy as determined from 30° stereoscopic photographs. The three methods were direct ophthalmoscopy through an undilated pupil, nonstereoscopic 45° retinal photography through a pharmacologically undilated pupil and nonstereoscopic 45° photography through a dilated pupil. A single 45° photograph centered between the disc and fovea was taken and direct ophthalmoscopy was performed on 99 persons prior to pharmacological dilation of the pupil. After dilation, another 45° photograph was taken of the same field, as well as 30° stereoscopic color photographs of DRS fields 1, 2 and 4 (modified). Corresponding photographic fields were graded by masked, trained graders for the severity of retinopathy and for the presence of specified diabetic lesions using the Modified Airlie House Classification scheme. For three levels of severity of retinopathy (none, nonproliferative or proliferative) exact agreement between direct ophthalmoscopy and grading of retinopathy from stereoscopic photographs taken with the standard 30° camera was 54.3\% (n = 94). For four levels of severity of retinopathy (none, microaneurysms only, all other nonproliferative retinopathy and proliferative retinopathy), exact agreement between gradings of retinopathy of the 45° photographs taken through undilated pupils and 30° photographs taken through dilated pupils was 82.5\% (n = 63); and for 45° photographs and 30° photographs taken through dilated pupils it was 86.5\% (n = 74): These data suggest that 45° nonstereoscopic fundus photographs, when graded according to a standard classification scheme, provide reasonably reliable photographic representation of the severity of retinopathy when broad overall categories are used.},
	number = {4},
	urldate = {2023-12-09},
	journal = {Ophthalmology},
	author = {Klein, Ronald and Klein, Barbara E. K. and Neider, Michael W. and Hubbard, Larry D. and Meuer, Stagy M. and Brothers, Rosemary J.},
	month = apr,
	year = {1985},
	keywords = {diabetic retinopathy, direct ophthalmoscopy, fundus camera, fundus photography, methodology},
	pages = {485--491},
}

@inproceedings{davis_relationship_2006,
	address = {New York, NY, USA},
	series = {{ICML} '06},
	title = {The relationship between {Precision}-{Recall} and {ROC} curves},
	isbn = {978-1-59593-383-6},
	url = {https://doi.org/10.1145/1143844.1143874},
	doi = {10.1145/1143844.1143874},
	abstract = {Receiver Operator Characteristic (ROC) curves are commonly used to present results for binary decision problems in machine learning. However, when dealing with highly skewed datasets, Precision-Recall (PR) curves give a more informative picture of an algorithm's performance. We show that a deep connection exists between ROC space and PR space, such that a curve dominates in ROC space if and only if it dominates in PR space. A corollary is the notion of an achievable PR curve, which has properties much like the convex hull in ROC space; we show an efficient algorithm for computing this curve. Finally, we also note differences in the two types of curves are significant for algorithm design. For example, in PR space it is incorrect to linearly interpolate between points. Furthermore, algorithms that optimize the area under the ROC curve are not guaranteed to optimize the area under the PR curve.},
	urldate = {2023-12-09},
	booktitle = {Proceedings of the 23rd international conference on {Machine} learning},
	publisher = {Association for Computing Machinery},
	author = {Davis, Jesse and Goadrich, Mark},
	month = jun,
	year = {2006},
	pages = {233--240},
}

@misc{paszke_pytorch_2019,
	title = {{PyTorch}: {An} {Imperative} {Style}, {High}-{Performance} {Deep} {Learning} {Library}},
	shorttitle = {{PyTorch}},
	url = {http://arxiv.org/abs/1912.01703},
	doi = {10.48550/arXiv.1912.01703},
	abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
	urldate = {2023-12-09},
	publisher = {arXiv},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	month = dec,
	year = {2019},
	note = {arXiv:1912.01703 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Mathematical Software, Statistics - Machine Learning},
}

@inproceedings{deng_imagenet_2009,
	address = {Miami, FL},
	title = {{ImageNet}: {A} large-scale hierarchical image database},
	isbn = {978-1-4244-3992-8},
	shorttitle = {{ImageNet}},
	url = {https://ieeexplore.ieee.org/document/5206848/},
	doi = {10.1109/CVPR.2009.5206848},
	abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a largescale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 5001000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classiﬁcation and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
	language = {en},
	urldate = {2023-12-09},
	booktitle = {2009 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and {Kai Li} and {Li Fei-Fei}},
	month = jun,
	year = {2009},
	pages = {248--255},
}

@misc{noauthor_amd_nodate,
	title = {{AMD} {Ryzen}™ {Threadripper}™ {Processors}},
	url = {https://www.amd.com/en/processors/ryzen-threadripper-pro},
	abstract = {AMD Ryzen™ Threadripper™ PRO W7000WX Series Processor based workstations are the ideal tools for artists, architects \& engineers. Get in touch to learn more!},
	language = {en},
	urldate = {2023-12-09},
}

@article{gao_parallel_2012,
	series = {Computational {Optical} {Measurement}},
	title = {Parallel computing in experimental mechanics and optical measurement: {A} review},
	volume = {50},
	issn = {0143-8166},
	shorttitle = {Parallel computing in experimental mechanics and optical measurement},
	url = {https://www.sciencedirect.com/science/article/pii/S0143816611001989},
	doi = {10.1016/j.optlaseng.2011.06.020},
	abstract = {Because of the merits of non-destruction, high speed, and high sensitivity, optical techniques have been developed for experimental mechanics and optical measurement. In commercial optical systems, the speed performance becomes more important and real-time systems are pursued. Among many acceleration methods, using parallel computing hardware is proven effective. In this paper, the main principles of parallel computing at an application level are introduced; the hardware platforms that support parallel computing are compared; the applications of parallel computing in experimental mechanics and optical measurement are reviewed. Parallel hardware platforms are seen to be useful for the acceleration of various problems. When the computation is time-consuming or real-time performance is required, hardware acceleration is a possible approach for consideration.},
	number = {4},
	urldate = {2023-12-09},
	journal = {Optics and Lasers in Engineering},
	author = {Gao, Wenjing and Kemao, Qian},
	month = apr,
	year = {2012},
	keywords = {Experimental mechanics, FPGA, GPU, Optical measurement, Parallel computing},
	pages = {608--617},
}

@misc{noauthor_research_nodate,
	title = {Research {Computing} {Home}},
	url = {https://rc.northeastern.edu/},
	abstract = {Northeastern University},
	language = {en-US},
	urldate = {2023-12-09},
	journal = {Research Computing},
}

@inproceedings{fatahalian_understanding_2004,
	address = {New York, NY, USA},
	series = {{HWWS} '04},
	title = {Understanding the efficiency of {GPU} algorithms for matrix-matrix multiplication},
	isbn = {978-3-905673-15-9},
	url = {https://doi.org/10.1145/1058129.1058148},
	doi = {10.1145/1058129.1058148},
	abstract = {Utilizing graphics hardware for general purpose numerical computations has become a topic of considerable interest. The implementation of streaming algorithms, typified by highly parallel computations with little reuse of input data, has been widely explored on GPUs. We relax the streaming model's constraint on input reuse and perform an in-depth analysis of dense matrix-matrix multiplication, which reuses each element of input matrices O(n) times. Its regular data access pattern and highly parallel computational requirements suggest matrix-matrix multiplication as an obvious candidate for efficient evaluation on GPUs but, surprisingly we find even near-optimal GPU implementations are pronouncedly less efficient than current cache-aware CPU approaches. We find the key cause of this inefficiency is that the GPU can fetch less data and yet execute more arithmetic operations per clock than the CPU when both are operating out of their closest caches. The lack of high bandwidth access to cached data will impair the performance of GPU implementations of any computation featuring significant input reuse.},
	urldate = {2023-12-09},
	booktitle = {Proceedings of the {ACM} {SIGGRAPH}/{EUROGRAPHICS} conference on {Graphics} hardware},
	publisher = {Association for Computing Machinery},
	author = {Fatahalian, K. and Sugerman, J. and Hanrahan, P.},
	month = aug,
	year = {2004},
	pages = {133--137},
}

@inproceedings{steinkraus_using_2005,
	address = {Seoul, South Korea},
	title = {Using {GPUs} for machine learning algorithms},
	isbn = {978-0-7695-2420-7},
	url = {http://ieeexplore.ieee.org/document/1575717/},
	doi = {10.1109/ICDAR.2005.251},
	abstract = {Using dedicated hardware to do machine learning typically ends up in disaster because of cost, obsolescence, and poor software. The popularization of Graphic Processing Units (GPUs), which are now available on every PC, provides an attractive alternative. We propose a generic 2-layer fully connected neural network GPU implementation which yields over 3X speedup for both training and testing with respect to a 3GHz P4 CPU.},
	language = {en},
	urldate = {2023-12-09},
	booktitle = {Eighth {International} {Conference} on {Document} {Analysis} and {Recognition} ({ICDAR}'05)},
	publisher = {IEEE},
	author = {Steinkraus, D. and Buck, I. and Simard, P.Y.},
	year = {2005},
	pages = {1115--1120 Vol. 2},
}

@misc{noauthor_nvidia_nodate,
	title = {{NVIDIA} {T4} {Tensor} {Core} {GPUs} for {Accelerating} {Inference}},
	url = {https://www.nvidia.com/en-us/data-center/tesla-t4/},
	abstract = {The world’s most efficient accelerator for accelerating the diverse applications of modern AI.},
	language = {en-us},
	urldate = {2023-12-09},
	journal = {NVIDIA},
}

@inproceedings{deng_imagenet_2009-1,
	title = {Imagenet: {A} large-scale hierarchical image database},
	booktitle = {2009 {IEEE} conference on computer vision and pattern recognition},
	publisher = {Ieee},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	year = {2009},
	pages = {248--255},
}

@misc{emily_apsey_tesla_2019,
	title = {{TESLA} {T4} {FOR} {VIRTUALIZATION}
NEW {GENERATION} {OF} {COMPUTER} {GRAPHICS} 
DRIVES {INCREASED} {VERSATILITY} {AND} {UTILIZATION}},
	shorttitle = {{TESLA} {T4} {FOR} {VIRTUALIZATION}},
	url = {https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/solutions/resources/documents1/Tesla-T4-for-Virtualization-Technology-Brief_Jan2019.pdf},
	language = {English},
	urldate = {2023-12-04},
	publisher = {NVIDIA},
	author = {Emily Apsey},
	month = jan,
	year = {2019},
}

@misc{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	doi = {10.48550/arXiv.1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2023-12-04},
	publisher = {arXiv},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv:1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{noauthor_diabetic_nodate,
	title = {Diabetic {Retinopathy} {Detection}},
	url = {https://kaggle.com/competitions/diabetic-retinopathy-detection},
	abstract = {Identify signs of diabetic retinopathy in eye images},
	language = {en},
	urldate = {2023-11-01},
}

@misc{noauthor_diabetic_nodate-1,
	title = {Diabetic {Retinopathy} {\textbar} {National} {Eye} {Institute}},
	url = {https://www.nei.nih.gov/learn-about-eye-health/eye-conditions-and-diseases/diabetic-retinopathy},
	urldate = {2023-11-01},
}
