\begin{abstract}

Given the wide-scale availability of high dimensional and high sample count datasets, primed for classification tasks, the need to move away from training neural-network based classifiers off device (on CPUs) and onto device (on GPUs) is ever growing. One such example of a domain where high dimensional data proliferates is in medical imaging applications. This paper evaluates the speedup present in training a set of Convolutional Neural Networks (CNNs) both on and off device over a Diabetic Retinopathy Disease Severity dataset containing FUNDUS images of the retina. Three CNN models are proposed, and the speedup present over a single epoch is compared across on device and off device training methods. Additionally, the overall accuracy of the three CNNs when trained over the respective Diabetic Retinopathy dataset are compared and shown to exceed a prediction based solely on the dataset's label distributions.

\end{abstract}
\begin{IEEEkeywords}
Parallelism, Convolutional Neural Networks, Diabetic Retinopathy
\end{IEEEkeywords}